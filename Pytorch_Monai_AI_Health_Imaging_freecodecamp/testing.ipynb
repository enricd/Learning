{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import(\n",
    "    Compose,\n",
    "    AddChanneld,\n",
    "    LoadImaged,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    "    Activations,\n",
    ")\n",
    "\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from monai.inferers import sliding_window_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = 'D:/Youtube/Organ and Tumor Segmentation/datasets/Task03_Liver/Data_Train_Test'\n",
    "model_dir = 'D:/Youtube/Organ and Tumor Segmentation/results/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"Results 25 june\", (12, 6))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Train dice loss\")\n",
    "x = [i + 1 for i in range(len(train_loss))]\n",
    "y = train_loss\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Train metric DICE\")\n",
    "x = [i + 1 for i in range(len(train_metric))]\n",
    "y = train_metric\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Test dice loss\")\n",
    "x = [i + 1 for i in range(len(test_loss))]\n",
    "y = test_loss\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Test metric DICE\")\n",
    "x = [i + 1 for i in range(len(test_metric))]\n",
    "y = test_metric\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n",
    "path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "path_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\n",
    "path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TestSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
    "test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
    "test_files = test_files[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"vol\", \"seg\"]),\n",
    "        Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
    "        CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
    "        Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
    "        ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256), \n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(model_dir, \"best_metric_model.pth\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_batch_size = 4\n",
    "roi_size = (128, 128, 64)\n",
    "with torch.no_grad():\n",
    "    test_patient = first(test_loader)\n",
    "    t_volume = test_patient['vol']\n",
    "    #t_segmentation = test_patient['seg']\n",
    "    \n",
    "    test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
    "    sigmoid_activation = Activations(sigmoid=True)\n",
    "    test_outputs = sigmoid_activation(test_outputs)\n",
    "    test_outputs = test_outputs > 0.53\n",
    "        \n",
    "    for i in range(32):\n",
    "        # plot the slice [:, :, 80]\n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"image {i}\")\n",
    "        plt.imshow(test_patient[\"vol\"][0, 0, :, :, i], cmap=\"gray\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"label {i}\")\n",
    "        plt.imshow(test_patient[\"seg\"][0, 0, :, :, i] != 0)\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(f\"output {i}\")\n",
    "        plt.imshow(test_outputs.detach().cpu()[0, 1, :, :, i])\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
